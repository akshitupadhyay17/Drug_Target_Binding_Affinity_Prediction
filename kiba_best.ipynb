{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb17400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 22:41:42.293228: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-10 22:41:42.831558: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-10 22:41:45.054196: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d006d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROT_LEN = 1200\n",
    "MAX_DRUG_LEN = 85\n",
    "EMBED_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cc454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 118254 samples from /teamspace/studios/this_studio/datasets/kiba.txt\n",
      "         drug_id protein_id                                         smiles  \\\n",
      "0  CHEMBL1087421     O00141  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "1  CHEMBL1087421     O14920  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "2  CHEMBL1087421     O15111  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "3  CHEMBL1087421     P00533  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "4  CHEMBL1087421     P04626  COC1=C(C=C2C(=C1)CCN=C2C3=CC(=C(C=C3)Cl)Cl)Cl   \n",
      "\n",
      "                                            sequence  affinity  \n",
      "0  MTVKTEAAKGTLTYSRMRGMVAILIAFMKQRRMGLNDFIQKIANNS...      11.1  \n",
      "1  MSWSPSLTTQTCGAWEMKERLGTGGFGNVIRWHNQETGEQIAIKQC...      11.1  \n",
      "2  MERPPGLRPGAGGPWEMRERLGTGGFGNVCLYQHRELDLKIAIKSC...      11.1  \n",
      "3  MRPSGTAGAALLALLAALCPASRALEEKKVCQGTSNKLTQLGTFED...      11.1  \n",
      "4  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...      11.1  \n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"/teamspace/studios/this_studio/datasets/kiba.txt\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH, \n",
    "    sep=r'\\s+',  # one or more spaces/tabs\n",
    "    header=None, \n",
    "    engine=\"python\",\n",
    "    names=[\"drug_id\", \"protein_id\", \"smiles\", \"sequence\", \"affinity\"]\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df)} samples from {DATA_PATH}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e537055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drugs: (118254, 85)\n",
      "Proteins: (118254, 1200)\n",
      "Affinities: (118254, 1)\n"
     ]
    }
   ],
   "source": [
    "all_smiles_chars = set(\"\".join(df[\"smiles\"].astype(str).values))\n",
    "all_smiles_chars = sorted(all_smiles_chars)\n",
    "\n",
    "smiles_token2idx = {}\n",
    "for index, char in enumerate(all_smiles_chars):\n",
    "    smiles_token2idx[char] = index + 1\n",
    "\n",
    "all_protein_aas = set(\"\".join(df[\"sequence\"].astype(str).values))\n",
    "all_protein_aas = sorted(all_protein_aas)\n",
    "\n",
    "protein_token2idx = {}\n",
    "for index, aa in enumerate(all_protein_aas):\n",
    "    protein_token2idx[aa] = index + 1\n",
    "\n",
    "def tokenize_smiles(smiles_string, max_len=MAX_DRUG_LEN):\n",
    "    tokens = []\n",
    "    for ch in smiles_string[:max_len]:\n",
    "        if ch in smiles_token2idx:\n",
    "            tokens.append(smiles_token2idx[ch])\n",
    "\n",
    "    padded_tokens = np.pad(tokens, pad_width=(0, max_len - len(tokens)), mode=\"constant\",constant_values=0)\n",
    "\n",
    "    return padded_tokens\n",
    "\n",
    "def tokenize_protein(sequence_string, max_len=MAX_PROT_LEN):\n",
    "    tokens = []\n",
    "    for ch in sequence_string[:max_len]:\n",
    "        if ch in protein_token2idx:\n",
    "            tokens.append(protein_token2idx[ch])\n",
    "\n",
    "    padded_tokens = np.pad(tokens, pad_width=(0, max_len - len(tokens)), mode=\"constant\",constant_values=0)\n",
    "\n",
    "    return padded_tokens\n",
    "\n",
    "drug_token_arrays = []\n",
    "for smiles in df[\"smiles\"]:\n",
    "    token_array = tokenize_smiles(smiles)\n",
    "    drug_token_arrays.append(token_array)\n",
    "\n",
    "protein_token_arrays = []\n",
    "for seq in df[\"sequence\"]:\n",
    "    token_array = tokenize_protein(seq)\n",
    "    protein_token_arrays.append(token_array)\n",
    "\n",
    "X_drug = np.vstack(drug_token_arrays)\n",
    "X_prot = np.vstack(protein_token_arrays)\n",
    "\n",
    "y = df[\"affinity\"].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "print(\"Drugs:\", X_drug.shape)\n",
    "print(\"Proteins:\", X_prot.shape)\n",
    "print(\"Affinities:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ccf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 94603\n",
      "Test size: 23651\n"
     ]
    }
   ],
   "source": [
    "X_prot_train, X_prot_test, X_drug_train, X_drug_test, y_train, y_test = train_test_split(\n",
    "    X_prot, X_drug, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "print(\"Train size:\", len(y_train))\n",
    "print(\"Test size:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490d1f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760136128.103272    2671 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21087 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:04.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ protein_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drug_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ protein_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │ drug_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,248</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,248</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ protein_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drug_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m2,688\u001b[0m │ protein_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m3,840\u001b[0m │ drug_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1197\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │     \u001b[38;5;34m16,416\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │     \u001b[38;5;34m16,416\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1192\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m77\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1185\u001b[0m, \u001b[38;5;34m96\u001b[0m)  │     \u001b[38;5;34m49,248\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m96\u001b[0m)    │     \u001b[38;5;34m49,248\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │    \u001b[38;5;34m197,632\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m1,049,600\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m513\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,105</span> (7.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,935,105\u001b[0m (7.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,105</span> (7.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,935,105\u001b[0m (7.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "protein_input = Input(shape=(MAX_PROT_LEN,), name=\"protein_input\")\n",
    "p_embed = Embedding(input_dim=len(all_protein_aas) + 1, output_dim=EMBED_DIM)(protein_input)\n",
    "p_conv1 = Conv1D(32, 4, activation=\"relu\", padding=\"valid\")(p_embed)\n",
    "p_conv2 = Conv1D(64, 6, activation=\"relu\", padding=\"valid\")(p_conv1)\n",
    "p_conv3 = Conv1D(96, 8, activation=\"relu\", padding=\"valid\")(p_conv2)\n",
    "p_flat = GlobalMaxPooling1D()(p_conv3)\n",
    "\n",
    "drug_input = Input(shape=(MAX_DRUG_LEN,), name=\"drug_input\")\n",
    "d_embed = Embedding(input_dim=len(all_smiles_chars) + 1, output_dim=EMBED_DIM)(drug_input)\n",
    "d_conv1 = Conv1D(32, 4, activation=\"relu\", padding=\"valid\")(d_embed)\n",
    "d_conv2 = Conv1D(64, 6, activation=\"relu\", padding=\"valid\")(d_conv1)\n",
    "d_conv3 = Conv1D(96, 8, activation=\"relu\", padding=\"valid\")(d_conv2)\n",
    "d_flat = GlobalMaxPooling1D()(d_conv3)\n",
    "\n",
    "merged = Concatenate()([p_flat, d_flat])\n",
    "dense1 = Dense(1024, activation=\"relu\")(merged)\n",
    "drop1 = Dropout(0.1)(dense1)\n",
    "dense2 = Dense(1024, activation=\"relu\")(drop1)\n",
    "drop2 = Dropout(0.1)(dense2)\n",
    "dense3 = Dense(512, activation=\"relu\")(drop2)\n",
    "output = Dense(1, activation=\"linear\")(dense3)\n",
    "\n",
    "model = Model(inputs=[protein_input, drug_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca819a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 22:42:14.161734: I external/local_xla/xla/service/service.cc:163] XLA service 0x758ca4005cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-10 22:42:14.161759: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2025-10-10 22:42:14.266904: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-10 22:42:14.864260: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-10 22:42:15.146919: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 22:42:17.116645: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1280', 9008 bytes spill stores, 10336 bytes spill loads\n",
      "\n",
      "2025-10-10 22:42:18.657084: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1832', 948 bytes spill stores, 948 bytes spill loads\n",
      "\n",
      "2025-10-10 22:42:18.904566: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2294', 716 bytes spill stores, 716 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  15/1331\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - loss: 134.9030 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760136144.764486    8179 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1330/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 12.5812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 22:42:41.288653: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1832', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 12.5741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 22:42:48.572749: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-10 22:42:49.512218: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 1064 bytes spill stores, 1068 bytes spill loads\n",
      "\n",
      "2025-10-10 22:42:50.778561: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 22:42:51.858757: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "2025-10-10 22:42:52.406590: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_152', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - loss: 3.0643 - val_loss: 0.5461 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.5750 - val_loss: 0.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.5302 - val_loss: 0.4612 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.5038 - val_loss: 0.4545 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4762 - val_loss: 0.4592 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4531 - val_loss: 0.4587 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4283 - val_loss: 0.4449 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4165 - val_loss: 0.4037 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4008 - val_loss: 0.3555 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3907 - val_loss: 0.3465 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3813 - val_loss: 0.3472 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3743 - val_loss: 0.3426 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3635 - val_loss: 0.3995 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3555 - val_loss: 0.3401 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3501 - val_loss: 0.3461 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3391 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3294 - val_loss: 0.3297 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3220 - val_loss: 0.3130 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3130 - val_loss: 0.3345 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3051 - val_loss: 0.3691 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3030 - val_loss: 0.2966 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2915 - val_loss: 0.2956 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2853 - val_loss: 0.3397 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2791 - val_loss: 0.3101 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2723 - val_loss: 0.2807 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2638 - val_loss: 0.2753 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2596 - val_loss: 0.2769 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2537 - val_loss: 0.2712 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2470 - val_loss: 0.2699 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2403 - val_loss: 0.2621 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2358 - val_loss: 0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2266 - val_loss: 0.2641 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2247 - val_loss: 0.2555 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2195 - val_loss: 0.2632 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2140 - val_loss: 0.2454 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2076 - val_loss: 0.2496 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.2035 - val_loss: 0.2551 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1955 - val_loss: 0.2478 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1926 - val_loss: 0.2352 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1894 - val_loss: 0.2364 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1832 - val_loss: 0.2359 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1789 - val_loss: 0.2359 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1733 - val_loss: 0.2344 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1682 - val_loss: 0.2317 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1634 - val_loss: 0.2253 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1568 - val_loss: 0.2312 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1563 - val_loss: 0.2219 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1479 - val_loss: 0.2242 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1446 - val_loss: 0.2113 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1394 - val_loss: 0.2201 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1353 - val_loss: 0.2136 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1318 - val_loss: 0.2118 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1272 - val_loss: 0.2079 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1253 - val_loss: 0.2091 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1203 - val_loss: 0.2033 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1164 - val_loss: 0.2125 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1139 - val_loss: 0.2009 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1114 - val_loss: 0.2294 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1063 - val_loss: 0.2079 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1057 - val_loss: 0.2173 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.1029 - val_loss: 0.1989 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0995 - val_loss: 0.2074 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0971 - val_loss: 0.1979 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0952 - val_loss: 0.1954 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0931 - val_loss: 0.1961 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0902 - val_loss: 0.1934 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0880 - val_loss: 0.1928 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0857 - val_loss: 0.1934 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0845 - val_loss: 0.1955 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0823 - val_loss: 0.1966 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0797 - val_loss: 0.2009 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0780 - val_loss: 0.2022 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0769 - val_loss: 0.1976 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0744 - val_loss: 0.1980 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0731 - val_loss: 0.1922 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0712 - val_loss: 0.1947 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0710 - val_loss: 0.1945 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0681 - val_loss: 0.1924 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0672 - val_loss: 0.1871 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0662 - val_loss: 0.1911 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0652 - val_loss: 0.1902 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0621 - val_loss: 0.1899 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0627 - val_loss: 0.1880 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0609 - val_loss: 0.1929 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0601 - val_loss: 0.1940 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0586 - val_loss: 0.1879 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0581 - val_loss: 0.2021 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0573 - val_loss: 0.1881 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0553 - val_loss: 0.1905 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0435 - val_loss: 0.1808 - learning_rate: 5.0000e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0408 - val_loss: 0.1823 - learning_rate: 5.0000e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0401 - val_loss: 0.1823 - learning_rate: 5.0000e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0391 - val_loss: 0.1798 - learning_rate: 5.0000e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0390 - val_loss: 0.1793 - learning_rate: 5.0000e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0387 - val_loss: 0.1807 - learning_rate: 5.0000e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0379 - val_loss: 0.1829 - learning_rate: 5.0000e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0367 - val_loss: 0.1840 - learning_rate: 5.0000e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0364 - val_loss: 0.1808 - learning_rate: 5.0000e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0360 - val_loss: 0.1852 - learning_rate: 5.0000e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0355 - val_loss: 0.1807 - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_prot_train, X_drug_train],\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d116b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "MSE: 0.1689\n",
      "RMSE: 0.4110\n",
      "CI: 0.8675\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_prot_test, X_drug_test])\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "def concordance_index(y_true, y_pred):\n",
    "    pairs = conc = 0\n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(i + 1, len(y_true)):\n",
    "            if y_true[i] != y_true[j]:\n",
    "                pairs += 1\n",
    "                if (y_pred[i] > y_pred[j] and y_true[i] > y_true[j]) or (y_pred[i] < y_pred[j] and y_true[i] < y_true[j]):\n",
    "                    conc += 1\n",
    "                elif y_pred[i] == y_pred[j]:\n",
    "                    conc += 0.5\n",
    "    return conc / pairs if pairs > 0 else 0\n",
    "\n",
    "ci = concordance_index(y_test.ravel(), y_pred.ravel())\n",
    "\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"CI: {ci:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c8e6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: /teamspace/studios/this_studio/models/kiba_better/deepdta_kiba_model.keras\n",
      "Weights saved at: /teamspace/studios/this_studio/models/kiba_better/deepdta_kiba.weights.h5\n",
      "Tokenizers saved at: /teamspace/studios/this_studio/models/kiba_better/tokenizers.pkl\n",
      "Training history saved at: /teamspace/studios/this_studio/models/kiba_better/training_history.json\n",
      "Results saved at: /teamspace/studios/this_studio/models/kiba_better/results.json\n",
      "Predictions saved at: /teamspace/studios/this_studio/models/kiba_better/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = r\"/teamspace/studios/this_studio/models/kiba_better\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(SAVE_DIR, \"deepdta_kiba_model.keras\")\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved at: {model_save_path}\")\n",
    "\n",
    "weights_path = os.path.join(SAVE_DIR, \"deepdta_kiba.weights.h5\")\n",
    "model.save_weights(weights_path)\n",
    "print(f\"Weights saved at: {weights_path}\")\n",
    "\n",
    "tokenizers_path = os.path.join(SAVE_DIR, \"tokenizers.pkl\")\n",
    "with open(tokenizers_path, \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"smiles_token2idx\": smiles_token2idx,\n",
    "        \"protein_token2idx\": protein_token2idx\n",
    "    }, f)\n",
    "print(f\"Tokenizers saved at: {tokenizers_path}\")\n",
    "\n",
    "history_path = os.path.join(SAVE_DIR, \"training_history.json\")\n",
    "with open(history_path, \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "print(f\"Training history saved at: {history_path}\")\n",
    "\n",
    "results_path = os.path.join(SAVE_DIR, \"results.json\")\n",
    "results = {\n",
    "    \"mse\": float(mse),\n",
    "    \"rmse\": float(rmse),\n",
    "    \"ci\": float(ci)\n",
    "}\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(f\"Results saved at: {results_path}\")\n",
    "\n",
    "preds_path = os.path.join(SAVE_DIR, \"predictions.csv\")\n",
    "pd.DataFrame({\n",
    "    \"y_true\": y_test.ravel(),\n",
    "    \"y_pred\": y_pred.ravel()\n",
    "}).to_csv(preds_path, index=False)\n",
    "print(f\"Predictions saved at: {preds_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
